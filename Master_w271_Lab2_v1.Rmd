---
title: "Statistical Methods for Discrete Response, Time Series, and Panel Data (W271): Lab 2"
author: "Mark Paluta, Carlos Sancini, & Krysten_Thompson"
output: 
  pdf_document:
  toc: true
  number_sections: true
fontsize: 11pt
geometry: margin=1in
---

# Strategic Placement of Products in Grocery Stores

In order to maximize sales, items within grocery stores are strategically placed to draw customer attention. This exercise examines one type of item-breakfast cereal. Typically, in large grocery stores, boxes of cereal are placed on sets of shelves located on one side of the aisle. By placing particular boxes of cereals on specific shelves, grocery stores may better attract customers to them. To investigate this further, a random sample of size 10 was taken from each of four shelves at a Dillons grocery store in Manhattan, KS. These data are given in the **cereal_dillons.csv** file. The response variable is the shelf number, which is numbered from bottom (1) to top (4), and the explanatory variables are the sugar, fat, and sodium content of the cereals.

```{r, warning=FALSE, message=FALSE}
# Tidy up the code for rendering pdf or html document
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)

# Clean up the working environment
rm(list = ls())

# Load Libraries
library(dplyr)
library(car)
library(Hmisc)
library(skimr)
library(ggplot2)

#library(stargazer)
library(gmodels) # For cross tabulation (SAS and SPSS style)

#library(MASS) # will use the polr function
#library(mcprofile)
library(vcd)
library(nnet)

## one at a time, table apply, pared, and public
#lapply(df[, c("apply", "pared", "public")], table)

## three way cross tabs (xtabs) and flatten the table
#ftable(xtabs(~ public + apply + pared, data = df))
```

```{r}
df_unscaled = read.csv("cereal_dillons.csv")
#head(df)
```

```{r}
str(df_unscaled)
```


a. The explanatory variables need to be reformatted before proceeding further. 
    - First, divide each explanatory variable by its serving size to account for the different serving sizes among the cereals. 
  
```{r}
df_unscaled = cbind(df_unscaled[, 1:4], df_unscaled[, 5:7]/df_unscaled[, 4])
df_unscaled$Shelf = as.factor(df_unscaled$Shelf)
```
  
    - Second, rescale each variable to be within 0 and 1.
```{r}

normalize = function(x) {
  (x - min(x))/(max(x) - min(x))
}

df = cbind(df_unscaled[, 1:4], apply(df_unscaled[,5:7], 2, normalize))

#confirm normalization worked
head(df) 
summary(df)
```


b. Construct side-by-side box plots with dot plots overlaid for each of the explanatory variables. 

```{r}
ggplot(df, aes(Shelf, sugar_g)) + 
  geom_boxplot(aes(fill = Shelf)) +
  geom_jitter() +
  ylab("Sugar") + 
  xlab("Shelf") +
  ggtitle("Cereal Sugar by Shelf") 

ggplot(df, aes(Shelf, fat_g)) + 
  geom_boxplot(aes(fill = Shelf)) +
  geom_jitter() +
  ylab("Fat") + 
  xlab("Shelf") +
  ggtitle("Cereal Fat by Shelf") 

ggplot(df, aes(Shelf, sodium_mg)) + 
  geom_boxplot(aes(fill = Shelf)) +
  geom_jitter() +
  ylab("Sodium") + 
  xlab("Shelf") +
  ggtitle("Cereal Sodium by Shelf") 

```


    - Also, construct a **parallel coordinates plot** for the explanatory variables and the shelf number. Discuss if possible content differences exist among the shelves.

```{r}
library(GGally) #Note this is a new library that we may have to justify
# [Mark]: We could ask Jeff but I think we are okay here.
#         I think his warning is more for statistics packages than visualization. 

df$Shelf = as.factor(df$Shelf)
ggparcoord(
  df, 
  columns = 5:7, 
  groupColumn='Shelf', 
  scale = 'globalminmax', 
  title = "Cereal sugar, fat and sodium by shef")
```


c. The response has values of $1, 2, 3,$ and $4$. Under what setting would it be desirable to take into account ordinality. Do you think that this setting occurs here?

**DRAFT -- If someone is analyzing where the placement of cereals labeled high-sugar or high-fat relative to the eye-level of the shopper is, labeling 'Shelf' and making it ordinal would be more useful in the analysis. It's not possible to tell whether Shelf 1 is the top shelf or bottom shelf when the shelves are numeric.**


d. Estimate a **multinomial regression model with linear forms of the sugar, fat, and sodium variables**. Perform **LRTs** to examine the importance of each explanatory variable.

```{r}
model = multinom(
  formula = Shelf ~ sugar_g + fat_g + sodium_mg, data=df, 
  epsilon = 0.0001, maxit = 1000, trace=F)
# (trace=F is suppressing convergence output for now)
summary(model)
round(coef(model), 2)

# type II test, each term after all others
Anova(model)

```

The estimated models are 

$log(\hat{\pi}_2/\hat{\pi}_1) = 6.90 + 2.69*sugar + 4.06 * fat - 17.49 * sodium$  
$log(\hat{\pi}_3/\hat{\pi}_1) = 21.68 - 12.22*sugar - 0.56 * fat - 24.98 * sodium$  
$log(\hat{\pi}_4/\hat{\pi}_1) = 21.29 - 11.39*sugar - 0.87 * fat - 24.67 * sodium$  

The LRT shows that sugar and sodium are statistically significant due low p-values while the fat variable has no significance and should be dropped from the model.

e. Show that there are no significant interactions among the explanatory variables (including an interaction among all three variables).

```{r}

# epsilon = 0.0001 and maxit = 1000 were set since some models were not converging
model.H0 = multinom(
  formula = Shelf ~ sugar_g + fat_g + sodium_mg, 
  data=df, trace = F, epsilon = 0.0001, maxit = 1000)

model.sugar.fat = multinom(
  formula = Shelf ~ sugar_g + fat_g + sodium_mg + sugar_g:fat_g, 
  data=df, trace = F, epsilon = 0.0001, maxit = 1000)

model.sugar.sodium = multinom(
  formula = Shelf ~ sugar_g + fat_g + sodium_mg + sugar_g:sodium_mg, 
  data=df, trace = F, epsilon = 0.0001, maxit = 1000)

model.fat.sodium = multinom(
  formula = Shelf ~ sugar_g + fat_g + sodium_mg + fat_g:sodium_mg, 
  data=df, trace = F, epsilon = 0.0001, maxit = 1000)

model.sugar.fat.sodium = multinom(
  formula = Shelf ~ sugar_g + fat_g + sodium_mg + sugar_g:fat_g:sodium_mg, 
  data=df, trace = F, epsilon = 0.0001, maxit = 1000)

# interacions significance test 
anova(model.H0, model.sugar.fat)
anova(model.H0, model.sugar.sodium)
anova(model.H0, model.fat.sodium)
anova(model.H0, model.sugar.fat.sodium)
```

The LRT hypothesis tests for each of the interactions shows that none of them have low enough p-values to be considered statistically significant.  

f. Kellogg's Apple Jacks (http://www.applejacks.com) is a cereal marketed toward children. For a serving size of $28$ grams, its sugar content is $12$ grams, fat content is $0.5$ grams, and sodium content is $130$ milligrams. Estimate the shelf probabilities for Apple Jacks.

```{r}
new_data = data.frame(
  sugar_g = 12/28/max(df_unscaled$sugar_g),
  fat_g = .5/28/max(df_unscaled$fat_g),
  sodium_mg = 130/28/max(df_unscaled$sodium_mg))

pi.hat = predict(object = model, newdata = new_data, type = "probs")
round(pi.hat*100,1)
```
The probability of being found on each shelf can be seen in the table above. Apple Jacks would most likely be found on Shelf 2 with nearly 50% probability.

g. Construct a plot similar to **Figure 3.3** where the estimated probability for a shelf is on the *y-axis* and the sugar content is on the *x-axis*. Use the mean overall fat and sodium content as the corresponding variable values in the model. Interpret the plot with respect to sugar content.

h. Estimate odds ratios and calculate corresponding confidence intervals for each explanatory variable. Relate your interpretations back to the plots constructed for this exercise.








